{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import edward as ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitive stochastic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use **Edward**'s models\n",
    "* Can create custom distributions using transforms or by inheriting directly from `RandomVariable`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing samples from unit Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 0.   # mean zero\n",
    "scale = 1. # unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = ed.models.Normal(loc, scale) # creates a normal distribution object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1.0821803\n",
      "log prob -1.5044956\n"
     ]
    }
   ],
   "source": [
    "x = normal.sample() # draws a sample from N(0, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vx, vlp = sess.run([x, normal.log_prob(x)])\n",
    "    print(\"sample\", vx)\n",
    "    print(\"log prob\", vlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Samples are named hierarchically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample Tensor(\"Normal/x/Reshape:0\", shape=(), dtype=float32) -0.9265542\n"
     ]
    }
   ],
   "source": [
    "x = normal.sample(name=\"x\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vx = sess.run(x)\n",
    "    print(\"sample\", x, vx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'sunny', 45.704914)\n",
      "(b'sunny', 71.09928)\n",
      "(b'cloudy', 67.831314)\n"
     ]
    }
   ],
   "source": [
    "def weather():\n",
    "    cloudy = ed.models.Bernoulli(0.3).sample(name=\"cloudy\")\n",
    "    cloudy = tf.cond(tf.equal(cloudy, 1), lambda: tf.constant('cloudy'), lambda: tf.constant('sunny'))\n",
    "    mean_temp = tf.cond(tf.equal(cloudy, 'cloudy'), lambda: tf.constant(55.0), lambda: tf.constant(75.0))\n",
    "    scale_temp = tf.cond(tf.equal(cloudy, 'cloudy'), lambda: tf.constant(10.0), lambda: tf.constant(15.0))\n",
    "    temp = ed.models.Normal(mean_temp, scale_temp).sample(name='temp')\n",
    "    return cloudy, temp\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    (cloudy, temp) = weather()\n",
    "    for _ in range(3):\n",
    "        print(sess.run((cloudy, temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.29641\n"
     ]
    }
   ],
   "source": [
    "def ice_cream_sales():\n",
    "    cloudy, temp = weather()\n",
    "    expected_sales = tf.cond(tf.equal(cloudy, \"sunny\"), lambda: tf.constant(200.0), lambda: tf.constant(50.0))\n",
    "    ice_cream = ed.models.Normal(expected_sales, 10.0).sample(name='ice_scream')\n",
    "    return ice_cream\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(ice_cream_sales()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Recursion, Higher-order Stochastic Functions, and Random Control Flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Edward** builds on **TensorFlow** and thus does not support general recursion.\n",
    "* Instead, it supports a restricted form of `while` loops (through `tf.while_loop`).\n",
    "* However, many recursive functions can still be converted into usages of `tf.while_loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "def geometric(p):\n",
    "    return tf.while_loop(\n",
    "        cond=lambda _: tf.equal(ed.models.Bernoulli(probs=p).sample(), 0), # name is automatically generated\n",
    "        body=lambda t: tf.add(t, 1),\n",
    "        loop_vars=[tf.constant(0)],\n",
    "    )\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    acc = sess.run(geometric(0.001))\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [100%] ██████████████████████████████ Elapsed: 8s | Acceptance Rate: 0.990\n",
      "mean 9.133204\n",
      "stddev 0.60152006\n"
     ]
    }
   ],
   "source": [
    "def scale(guess):\n",
    "    var = 1.0\n",
    "    # The prior over weight encodes our uncertainty about our guess\n",
    "    weight = ed.models.Normal(guess, var)\n",
    "    # This encodes our belief about the noisiness of the scale:\n",
    "    # the measurement fluctuates around the true weight\n",
    "    measurement = ed.models.Normal(weight, 0.75)\n",
    "    return weight, measurement\n",
    "\n",
    "weight, measurement = scale(8.5)\n",
    "posterior = ed.models.Empirical(tf.Variable(tf.zeros(10000)))\n",
    "inference = ed.HMC({weight: posterior}, {measurement: 9.5})\n",
    "inference.run()\n",
    "vmean, vstd = ed.get_session().run((posterior.mean(), posterior.stddev()))\n",
    "print(\"mean\", vmean)\n",
    "print(\"stddev\", vstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [100%] ██████████████████████████████ Elapsed: 9s | Loss: 0.975\n",
      "mean 9.500995\n",
      "stddev 0.5999705\n"
     ]
    }
   ],
   "source": [
    "def guide(guess):\n",
    "    qalpha = tf.Variable(ed.models.Uniform(0.0, 1.0).sample() + guess, name='a')\n",
    "    qbeta = tf.Variable(ed.models.Uniform(0.0, 1.0).sample(), name='b')\n",
    "    qweight = ed.models.Normal(qalpha, qbeta)\n",
    "    return qalpha, qbeta, qweight\n",
    "\n",
    "guess = tf.Variable(8.5)\n",
    "weight, measurement = scale(guess)\n",
    "qalpha, qbeta, qweight = guide(guess)\n",
    "inference = ed.KLqp({weight: qweight}, {measurement: 9.5})\n",
    "inference.run(n_samples=10, n_iter=10000)\n",
    "vmean, vstd = ed.get_session().run((qalpha, qbeta))\n",
    "print(\"mean\", vmean)\n",
    "print(\"stddev\", vstd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
