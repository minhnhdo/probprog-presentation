{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pyprob\n",
    "from pyprob import util, Model\n",
    "from pyprob.distributions import Normal, Uniform, Categorical\n",
    "\n",
    "pyprob.set_verbosity(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyProb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **PyProb** is a PyTorch-based probabilistic programming language\n",
    "* It supports **inference compilation** with minimal intervention\n",
    "* It uses a protocol (PPX) that allows **distributed** training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitive Stochastic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Built on top of **PyTorch's** distributions library\n",
    "* API is, however, slightly different than Pyro's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing sample from unit Normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.\n",
    "sigma = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = Normal(mu, sigma) # create a normal distribution object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample tensor(-0.0271)\n",
      "log prob tensor(-0.9193)\n"
     ]
    }
   ],
   "source": [
    "x = normal.sample() # draw a sample from N(0,1)\n",
    "print(\"sample\", x)\n",
    "print(\"log prob\", normal.log_prob(x)) # score the sample from N(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just like in the Pyro examples, these distributions and sampling functions are backed by the underlying PyTorch implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6212)\n"
     ]
    }
   ],
   "source": [
    "x = Normal(mu, sigma).sample()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No need to explicitly pass a name to the random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Ice-Cream Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s suppose we have a bunch of data with daily mean temperatures and cloud cover. We want to reason about how temperature interacts with whether it was sunny or cloudy. A simple stochastic function that does that is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cloudy', tensor(43.7089))\n",
      "('sunny', tensor(78.6348))\n",
      "('sunny', tensor(71.9160))\n"
     ]
    }
   ],
   "source": [
    "def weather():\n",
    "    cloudy = Uniform(0, 1).sample()\n",
    "    cloudy = 'cloudy' if cloudy < 0.3 else 'sunny'\n",
    "    mean_temp = {'cloudy': 55.0, 'sunny': 75.0}[cloudy]\n",
    "    scale_temp = {'cloudy': 10.0, 'sunny': 15.0}[cloudy]\n",
    "    temp = Normal(mean_temp, scale_temp).sample()\n",
    "    return cloudy, temp\n",
    "    \n",
    "for _ in range(3):\n",
    "    print(weather())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ice_cream_sales():\n",
    "    cloudy, temp = weather()\n",
    "    expected_sales = 200. if cloudy == 'sunny' and temp > 80.0 else 50.\n",
    "    return Normal(expected_sales, 10.0).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36.1148)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_cream_sales()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference: One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianUnknownMean(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Gaussian with unknown mean\") # give the model a name\n",
    "        \n",
    "        # prior mean and std\n",
    "        self.prior_mean = 1\n",
    "        self.prior_stdd = math.sqrt(5)\n",
    "        self.likelhood_stdd = math.sqrt(2)\n",
    "\n",
    "    # Needed to specifcy how the generative model is run forward\n",
    "    def forward(self):\n",
    "        # sample the (latent) mean variable to be inferred:\n",
    "        mu = pyprob.sample(Normal(self.prior_mean, self.prior_stdd))\n",
    "\n",
    "        # define the likelihood\n",
    "        likelihood = Normal(mu, self.likelhood_stdd)\n",
    "\n",
    "        # observation \"placeholders\"\n",
    "        # these can have concrete values associated with them later when\n",
    "        # conditioning on data.\n",
    "        pyprob.observe(likelihood, name='observation-1')\n",
    "        pyprob.observe(likelihood, name='observation-2')\n",
    "\n",
    "        # return the latent quantity of interest\n",
    "        return mu\n",
    "\n",
    "# create an instance of the model\n",
    "gum = GaussianUnknownMean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probabilistic program above models **Gaussian with Unknown Mean**: our goal is to infer the expected value of `mu` above.\n",
    "* PyProb supports multiple inference algorithms, including inference compilation (discussed later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor(6.7454)\n",
      "stddev: tensor(0.7475)\n"
     ]
    }
   ],
   "source": [
    "posterior = gum.posterior_distribution(\n",
    "    num_traces=1000, # number of samples to be used\n",
    "    inference_engine=pyprob.InferenceEngine.IMPORTANCE_SAMPLING, # the inference algorithm\n",
    "    observe={'observation-1': 9, 'observation-2': 8} # conditioning on some observations\n",
    ")\n",
    "\n",
    "# inferring the mean and standard deviation of our `mu` latent variable\n",
    "print(\"mean:\", posterior.mean)\n",
    "print(\"stddev:\", posterior.stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PyProb provides other inference algorithms too:\n",
    "    * Importance sampling\n",
    "    * Lightweight Metropolis-Hastings\n",
    "    * Random Walk Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyProb supports **inference compilation**. Let's apply that to the _Gaussian with Unknown Mean_ example we used in the last section. Recall that we defined a model for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GaussianUnknownMean at 0x7f2b252a8d68>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyProb provides an inference engine to use in combination with a **learned inference network**.\n",
    "\n",
    "First, we need to learn the inference network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new inference network...\n",
      "Initializing inference network...\n",
      "Observable observation-1: observe embedding not specified, using the default FEEDFORWARD.\n",
      "Observable observation-1: embedding depth not specified, using the default 2.\n",
      "Observable observation-2: observe embedding not specified, using the default FEEDFORWARD.\n",
      "Observable observation-2: embedding depth not specified, using the default 2.\n",
      "New proposal layer for address: 16__forward__mu__Normal__1\n",
      "Total number of parameters: 5,834\n",
      "Train. time | Trace     | Init. loss| Min. loss | Curr. loss| T.since min | Traces/sec\n",
      "0d:00:00:02 | 1,024     | +2.21e+00 | +2.16e+00 | \u001b[31m+2.19e+00\u001b[0m | 0d:00:00:00 | 405.0                              \n"
     ]
    }
   ],
   "source": [
    "gum.learn_inference_network(\n",
    "    num_traces=1000, # how many traces (executions of the generative model) to use to train the inference network\n",
    "    observe_embeddings={\n",
    "        'observation-1': {'dim': 10},\n",
    "        'observation-2': {'dim': 10}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the inference network is **trained** with the traces produced by the generative model, we can use it to perform **inference**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor(7.4163)\n",
      "stddev: tensor(1.0121)\n"
     ]
    }
   ],
   "source": [
    "posterior = gum.posterior_distribution(\n",
    "    num_traces=1000,\n",
    "    inference_engine=pyprob.InferenceEngine.IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK,\n",
    "    observe={'observation-1': 9, 'observation-2': 8.4}\n",
    ")\n",
    "\n",
    "# inferring the mean and standard deviation of our `mu` latent variable\n",
    "print(\"mean:\", posterior.mean)\n",
    "print(\"stddev:\", posterior.stddev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Compilation: Solving Captchas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "class MiniCaptcha(Model):\n",
    "    _alphabet = [\n",
    "        'A', 'b', 'C', 'd', 'E', 'f', 'G', 'h', 'I', 'j', 'K', 'l', 'M',\n",
    "        'n',  'O', 'p', 'Q', 'r', 'S', 't', 'U', 'v', 'X', 'w', 'Y', 'z'\n",
    "    ]\n",
    "    \n",
    "    _fonts = [\n",
    "        'Ubuntu-B.ttf',\n",
    "        'FFF_Tusj.ttf',\n",
    "        'LobsterTwo-Regular.otf',\n",
    "        'SHPinscher-Regular.otf'\n",
    "    ]\n",
    "\n",
    "    def __init__(self, alphabet=_alphabet, fonts=_fonts, noise=0.1):\n",
    "        self._alphabet = alphabet\n",
    "        self._letter_probs = [1/len(alphabet) for i in range(len(alphabet))]\n",
    "        self._font_probs = [1/len(fonts) for i in range(len(fonts))]\n",
    "        self._noise = noise\n",
    "        super().__init__('MiniCaptcha')\n",
    "        \n",
    "    def render_canvas(self, text, font, size=18, height=28, width=28, x=6, y=6):\n",
    "        pil_font = ImageFont.truetype(font, size=size)\n",
    "        text_width, text_height = pil_font.getsize(text)\n",
    "        canvas = Image.new('RGB', [height, width], (255, 255, 255))\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "        draw.text((x, y), text, font=pil_font, fill='#000000')\n",
    "        return canvas\n",
    "\n",
    "    def render(self, text, font, size=18, height=28, width=28, x=6, y=6):\n",
    "        canvas = self.render_canvas(text, font, size, height, width, x, y)\n",
    "        return torch.from_numpy(1 - (np.asarray(canvas) / 255.0))[:, :, 0].unsqueeze(0).float()\n",
    "    \n",
    "    def forward_canvas(self):\n",
    "        letter_id = Categorical(self._letter_probs).sample()\n",
    "        font_id = Categorical(self._font_probs).sample()\n",
    "        \n",
    "        image = self.render_canvas(self._alphabet[letter_id], self._fonts[font_id])\n",
    "        return image\n",
    "\n",
    "    def forward(self):\n",
    "        letter_id = pyprob.sample(Categorical(self._letter_probs))\n",
    "        font_id = pyprob.sample(Categorical(self._font_probs))\n",
    "        \n",
    "        image = self.render(self._alphabet[letter_id], self._fonts[font_id]).view(-1)\n",
    "        likelihood = Normal(image, self._noise)\n",
    "        pyprob.observe(likelihood, name='query_image')\n",
    "        return letter_id\n",
    "            \n",
    "captcha_model = MiniCaptcha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAArUlEQVR4nO3UMQrEIBAF0HEJCMFCi/RJ50E8gIWlR0jvJXK5NFYeIqRIN5ktFhY2yBauLAT8naiPaeYzIoLaeVQXG9rQf6EhBCGEcw4RS1TKhXP+uk0pZR98T37SeZ77vrfWjuNYMCi7+e4bYxhjUsqa6I9paEOvOc8TALquK0Ov3/Z9P44jxggA0zRVQLdtU0q9j977MvSj+tZ1HYaBc661XpYFEQt6j4ju01JPe6C2DTS1IX0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA5klEQVR4nO2WsQqDMBCGL6XIHYo+goKDeQg3h4AvpPgojj6K7m6Cq4tOWRziIJgOhUJbUcEuBb8t5PjyX45AmNYafs3t58ZLekkv6SV9I89zIYTneYiIiJzzJEmklEeteo0oir4rXdft+361/oOt9m3bnqZJSpmmKQB0XZdl2dmkjuM8l8uy+L7/POZs0heMMc45AIzjqJTarT86/WEYAICIiOiUdJ7npmmUUkVR1HUNAHEcM8b2IxyfPiK2bXv2Tg3DCMPQNE3LsoQQZVkGQbAfE+C+sUdEVVUdsXzwP2+f6X/5oTwAaWnzBuTeDD0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABe0lEQVR4nO3VscrCMBAH8GvBKWhFFKc62KnFimCbvQ/g7uB7+B4+h0NdXdwTXFpNsYMV1KniIoigtt9w4FQKX3XsfwoJ9+NyGSKlaQq/jvxzsURLtEQzEobheDxWVVXTtOv1ipvn89lxHMdx3u93nppmZbFYDAaD7XarqioArFYr3J/P51gVx3FmISYDPRwO1WqVc3673SRJAoDZbIZH0+kU0SAIctCM67uuK8uyZVlYCQCe5+ERYwwXl8vlfzONoqhSqWA7mqZ90CRJ1uu1YRhF0Mlk8nq9jsejEGI0GhFCNptNkiS73U5RFNM0i6CWZZ1OJ0KIEMI0zV6vd7/f9/s9Y4xS2mq1iqAAQAhpNBpBEBiG0e/3AcDzPM45pbTZbBZEAeDxeERRpOs6or7vM8Zs2/4KDcOw3W4rioIo59z3/eFw+BUqhMCHRnS5XHa73VqtVnymAIADBYB6vd7pdJ7PJ6UUAL7tVNd1XGOztm1/0DiOc1Cp/Pd/nj+xQiHOEibUqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA1UlEQVR4nO3UIQqEQBgF4Pcvi3XQKFajmC0yIFYvIBYvZLV7AqtRPIIGm5gMeoYxGHZBZlfZKQvz0gwMHzweDAkhoDoP5aJGNapRjb4yDAMRZVmmEj0yz3Mcx4yxKIqmabqnilP6vgdgWVZd12VZGobhed752YdI0TRNj2ue5wDatr2OSusT0XEIggDAOI7X239f3zRNANu2qUSXZQFg27ZKtGkaAL7vX0elQ7mu23VdURQAOOdq1uech2HIGEuSZF3XW+hT1sBxnKqqblR+y19/KL9nB6WAN6jc5XbWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA70lEQVR4nO3VMaqEMBQF0BcRBEEtBUFsXIA7EUsrO0sLSxGXYeUSLO1cgUuws8gK1FbuL17jZ/6fDDM2A94qXMgJhBciANDV0S4Xb/RGb/RXsiwTQggh8jw/92VZcl9VlULFQ6SUpmkSka7r8zxzuSyLYRhE5Lruuq6Pu875AwXQNA0fmSQJN2mactN13XPxX3Tfd8/zWBmGYRxHXkdRdBzHmyiAvu8ZCoIgDEMi0jRtmial+AwFEMfx+faLonhFVKBSStu2WfR9f9u2C1AAdV0z2rbtiyIAxfA7jsMLy7IUs3nKVz/TzyNwf9Ffgf4A98DmEeSPs9kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAA10lEQVR4nO3VIQqEUBAG4H/2AF7AYraoYPMKVg1mj+ABTHaxewaDYLDbrDbB4hm0jWHCLijirpaF96ef4fHN45VHzIyn83pcVKhCFarQd6IoIiIiGoZBJn3fyyRJkh/RMAylNE0jpa5rKUEQXLoq77Isi6ZpADzPk4lt2wAMw9gfPswBysxxHAMgonmex3GU9Wma3kK7rhMoz/Msy2TBNE23UGa2LAuA67qmaQLwff+ieIaWZfn59G3bPoCu66rruoiO41wXz1BmLopC0KqqvkKJ1Rf9F+gG7nf9FdA4i5IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAArElEQVR4nO2VMQrEIBBFR9kiCMEqJ8gxPIOth7HKEXIkL2KwFVKIoK1bSLYaQhJkYRdfNzo8+DOIpJQCraHNjV3apV+UWmuVUtM0DcMwz/O6rtelL/TUey+E8N7Xcts2Su9kKhjLstRbrXWM0Tm37zvaiYJLpZQAQAhJKV13fcBD5ZwBYBxHxtiN1Adnk4oxkgNjTBvpY/DtVzjnIYQH0j94UV36GNK/6N+QvgE6dbWuB8pBIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABhElEQVR4nO3UMc/BQBgH8Gt7TnrXXulAbCQWk01sFhI7ia9g9SUQo48gPoPFgERirYiwG0TPJOGU1L27VHLoInmf9ZJf/k+ey18RQoCwRw1d/Ef/0fAHvnoQQvR6PcdxdrtdvV7HGM/n88FgIIMGJ93v9/1+37IsTdNqtRpjDEKYTqclkwajs9nMcRxd15PJZKvVqlar0Wi02WxKosHru65bqVTu9zvGGABQLBbz+TylVBJVngplMplsNpvpdEoIoZSu1+tGo8EYK5fLhUJBEn1e/3q9Ho9Hznkul7Nt+/F4IIQopfIxA5LebjeEULfbzWQyGOPFYtFut+W54KQIIQCAaZqqqmqa5nneuyJ4dSgIoeu6hBDf9z9Ag7+UaZq+71uWZRhGaGgkEonH457ncc4/QAPWF0JwzkejUSqVWi6X5/NZ13VVfaMlnq8PAOh0OuPxuFQq2ba9Wq0IIYyx4XD4Fbrdbg+HQyKRMAzjdDrFYrHL5ZLNZhVF+Rz9fn6npH8H/QN0epdwBpgVSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABbUlEQVR4nO3UO6rCQBgF4DPRRHyE0SIGERGxEtyGbsDSOr2bsbB0ETYWFoILsNAuRQoVHwQkJKJJ5r+FcLl4FYymETzlMHxzhn8YRkSIO1Ls4hf9oh+NCiEAEJHv+y+gyf9Ltm2PRqN6vX44HNLpdKvVigFVVXU6nXqe57puo9EAEARBMnln56PcXv98PsuyLMuyoiiMMUVRAIRh+FbT8XhsmqbneZlMZr1eDwaD+Xxumma/33+9aT6fr1Qq+/3esqztdlsoFEqlkqZpl8vleZTd/KdExBjrdDq6rruu2263u93u89z9powxAMVisVarcc5TqdT1pEjo/ZnmcjnOeTabPZ1OAIQQiUTi9abXhGEoSZLv+7ZtA4gkPkQBEJEQYrPZAAiCINKgHqKz2cxxnOVyORwOe73earV6FzUMo1wuE5GmaZPJZLfb6br+PHr7pP7GsqzFYlGtVomo2WzGg/7meDxyzmNGo+Zzfv4fKnmgVpOiQ2UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABgElEQVR4nO3WMarCQBAA0FmzQoIIamMjChIsFLTxCl5BsLEPOUbSaKd4AQsLKxt7bcwNFCxMY5qIqTRWhvnFQBDNRoI2H5xqmdl57O6kCENE+Hakvi7+0B/6Q6PD8zzDMNrtdjabVRSlVqtpmrbb7d6rKIjNZlMsFl/3c84nk4moiyIadRwnn88DgCRJpmmez2ff9+fzOSUZY8vlMjGqaRqdyzTNx/xqtaJ8o9FIjNLFOefX6/Wp1Gw2yT0cDiI0YlC+77uuCwDlcjmTyTxV6/U6LWzbFs0pAr3f77RgjL1Ww2QQBCI0+vq5XA4A0un07XZ7KrVaLWrc7/fJ3rTX61HnYDB4zK/Xa8qrqioSheh2u5VlGQA458Ph0PM8+qQKhQKhs9ksMYqIi8VCUZSIIaRS4/E4RoxDEdG2bV3XK5VKOKJut2tZVrz4Bg2j3++Tq+u6ZVmn0ykIgk/R4/FYrVYfH2E6nX6KIuLlchmNRp1Op1QqybLsum7MZob/5Q/lD7LvL3d+LFXlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython\n",
    "import io\n",
    "\n",
    "for _ in range(10):\n",
    "    canvas = captcha_model.forward_canvas()\n",
    "    bytes = imgByteArr = io.BytesIO()\n",
    "    canvas.save(bytes, format='PNG')\n",
    "\n",
    "    IPython.display.display(IPython.display.Image(bytes.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Categorical(num_categories: 26, probs:tensor([1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e+00,\n",
      "        1.0000e-08, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e+00, 1.0000e-08])), Categorical(num_categories: 26, probs:tensor([1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08, 1.0000e-08,\n",
      "        1.0000e-08, 1.0000e+00]))]\n"
     ]
    }
   ],
   "source": [
    "def one_hot(dim, i):\n",
    "    t = torch.zeros(dim)\n",
    "    t.narrow(0, i, 1).fill_(1)\n",
    "    return t\n",
    "\n",
    "epsilon = 1e-8\n",
    "\n",
    "true_posteriors = [\n",
    "    Categorical(one_hot(len(MiniCaptcha._alphabet), i) + epsilon) for i in range(len(MiniCaptcha._alphabet))\n",
    "]\n",
    "\n",
    "print(true_posteriors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new inference network...\n",
      "Initializing inference network...\n",
      "New proposal layer for address: 12__forward__letter_id__Categorical(len_probs:26)_...\n",
      "New proposal layer for address: 28__forward__font_id__Categorical(len_probs:4)__1\n",
      "Total number of parameters: 455,138\n",
      "Train. time | Trace     | Init. loss| Min. loss | Curr. loss| T.since min | Traces/sec\n",
      "0d:00:00:09 | 1,024     | +4.64e+00 | +4.62e+00 | \u001b[32m+4.63e+00\u001b[0m | 0d:00:00:01 | 109.0                              \n"
     ]
    }
   ],
   "source": [
    "# Training the inference network\n",
    "\n",
    "captcha_model.learn_inference_network(\n",
    "    num_traces=1000,\n",
    "    observe_embeddings={'query_image': {'dim': 32,\n",
    "                                        'reshape': [1, 28, 28],\n",
    "                                        'embedding': pyprob.ObserveEmbedding.CNN2D5C}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "KL-divergence of all posterior distributions: 9.536744300930877e-07\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "alphabet = MiniCaptcha._alphabet\n",
    "choose_font = lambda: MiniCaptcha._fonts[random.randint(0, len(MiniCaptcha._fonts) - 1)]\n",
    "\n",
    "test_images = [captcha_model.render(letter, choose_font()).view(-1) for letter in alphabet]\n",
    "\n",
    "posteriors = []\n",
    "estimates = []\n",
    "\n",
    "for i in range(len(alphabet)):\n",
    "    posterior = captcha_model.posterior_distribution(\n",
    "        1000,\n",
    "        pyprob.InferenceEngine.IMPORTANCE_SAMPLING_WITH_INFERENCE_NETWORK,\n",
    "        observe={'query_image': test_images[i]}\n",
    "    )\n",
    "    \n",
    "    posteriors.append(posterior)\n",
    "    estimates.append(alphabet[int(posterior.mode)])\n",
    "\n",
    "correct_estimates = sum([1 if estimates[i] == alphabet[i] else 0 for i in range(len(alphabet))])\n",
    "accuracy = correct_estimates / len(alphabet)\n",
    "\n",
    "kl_divergence = float(sum([pyprob.distributions.Distribution.kl_divergence(\n",
    "    util.empirical_to_categorical(posterior, max_val=len(alphabet) - 1), true_posterior)\n",
    "                           for (posterior, true_posterior) in zip(posteriors, true_posteriors)]))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"KL-divergence of all posterior distributions:\", kl_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
